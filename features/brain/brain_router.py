import threading
from core.event_bus import bus
from features.brain.slm_client import LocalBrain
from features.brain.gemini_client import GeminiBrain

class BrainRouter:
    def __init__(self):
        # åˆå§‹åŒ–å…©å€‹å¤§è…¦
        self.local_brain = LocalBrain(model_name="gemma2:2b") # ç¢ºä¿ä½ æœ‰ ollama run gemma2:2b
        self.cloud_brain = GeminiBrain()
        
        # â˜… é€™æ˜¯å…¨å®¶å”¯ä¸€è½ä½¿ç”¨è€…èªªè©±çš„è€³æœµ
        bus.user_sent_message.connect(self.dispatch)
        print("ğŸ§  å¤§è…¦è·¯ç”±å™¨å·²å•Ÿå‹•ï¼šOllama å„ªå…ˆ -> Gemini å‚™æ´")

    def dispatch(self, text):
        # å•Ÿå‹•åŸ·è¡Œç·’ï¼Œé¿å… GUI å¡æ­»
        task = threading.Thread(target=self.logic_process, args=(text,), daemon=True)
        task.start()

    def logic_process(self, text):
        # 1. ç™¼é€æ€è€ƒè¨Šè™Ÿ (è®“ Doro åˆ‡æ›å‹•ç•«)
        bus.gemini_thinking.emit() 
        
        # 2. å„ªå…ˆå˜—è©¦åœ°ç«¯ (Ollama)
        print(f"ğŸ  åœ°ç«¯å˜—è©¦è™•ç†: {text}")
        success, local_reply = self.local_brain.think(text)
        
        # 3. åˆ¤æ–·æ˜¯å¦éœ€è¦åˆ‡æ›é›²ç«¯ (Fallback Logic)
        needs_cloud = False
        
        if not success:
            print(f"âš ï¸ åœ°ç«¯å¤±æ•— ({local_reply}) -> åˆ‡æ›é›²ç«¯")
            needs_cloud = True
        elif "[NEED_GEMINI]" in local_reply:
            print("ğŸ”„ åœ°ç«¯åˆ¤æ–·ç„¡æ³•å›ç­” -> åˆ‡æ›é›²ç«¯")
            needs_cloud = True
        elif len(local_reply) < 2:
            print("âš ï¸ åœ°ç«¯å›è¦†å¤ªçŸ­ -> åˆ‡æ›é›²ç«¯")
            needs_cloud = True

        # 4. åŸ·è¡Œåˆ†æµ
        if needs_cloud:
            # å‘¼å« Gemini (å®ƒè£¡é¢åŒ…å«äº† StockTool è‚¡ç¥¨æŸ¥è©¢é‚è¼¯)
            self.cloud_brain.run_api_request(text)
        else:
            print("âœ… åœ°ç«¯æˆåŠŸå›è¦†")
            # ç™¼é€è¨Šè™Ÿçµ¦ UI é¡¯ç¤ºæ°£æ³¡
            bus.doro_response_ready.emit(local_reply)